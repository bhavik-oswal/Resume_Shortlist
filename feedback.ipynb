{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f530a498-2f3a-4e10-9218-fe2f8b8e1df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Resume and Job Description Evaluator with NLP Enhancements ===\n",
      "\n",
      "Synthetic Resume:\n",
      "Data Analysis. Experience in TensorFlow and PyTorch..\n",
      "\n",
      "Synthetic Job Description:\n",
      "Job role: AI Researcher. Required skills: Big Data, SQL, TensorFlow, Deep Learning, NLP.\n",
      "\n",
      "=== Feedback ===\n",
      "Match Percentage: 15.38%\n",
      "Cosine Similarity: 11.91\n",
      "Matching Keywords: data, tensorflow\n",
      "Missing Keywords: role, required, ai, deep, job, learning, skills, big, researcher, sql, nlp\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a list of stopwords\n",
    "STOPWORDS = nlp.Defaults.stop_words\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text.lower())\n",
    "    # Remove stopwords and punctuation, and return clean tokens\n",
    "    return [token.text for token in doc if token.is_alpha and token.text not in STOPWORDS]\n",
    "\n",
    "# Extract keywords from text\n",
    "def extract_keywords(text):\n",
    "    tokens = preprocess_text(text)\n",
    "    return set(tokens)\n",
    "\n",
    "# Generate synthetic data for testing purposes\n",
    "def generate_synthetic_resume():\n",
    "    skills = [\"Python\", \"Machine Learning\", \"Data Analysis\", \"SQL\", \"TensorFlow\", \"Deep Learning\", \"Pandas\", \"NLP\"]\n",
    "    experiences = [\n",
    "        \"Worked on machine learning models.\",\n",
    "        \"Performed data analysis using Python.\",\n",
    "        \"Experience in TensorFlow and PyTorch.\",\n",
    "        \"Strong knowledge of data pipelines.\"\n",
    "    ]\n",
    "    return f\"{random.choice(skills)}. {random.choice(experiences)}.\"\n",
    "\n",
    "def generate_synthetic_job_description():\n",
    "    job_roles = [\n",
    "        \"Machine Learning Engineer\", \"Data Scientist\", \"Software Developer\", \"AI Researcher\"\n",
    "    ]\n",
    "    job_keywords = [\n",
    "        \"Python\", \"TensorFlow\", \"SQL\", \"Data Visualization\", \"Deep Learning\",\n",
    "        \"NLP\", \"Pandas\", \"Scikit-learn\", \"Big Data\", \"Artificial Intelligence\"\n",
    "    ]\n",
    "    description = f\"Job role: {random.choice(job_roles)}. Required skills: {', '.join(random.sample(job_keywords, 5))}.\"\n",
    "    return description\n",
    "\n",
    "# Evaluate resume against the job description\n",
    "def evaluate_resume(resume_text, job_description):\n",
    "    # Extract keywords from both texts\n",
    "    resume_keywords = extract_keywords(resume_text)\n",
    "    job_keywords = extract_keywords(job_description)\n",
    "\n",
    "    # Find matching and missing keywords\n",
    "    matching_keywords = resume_keywords.intersection(job_keywords)\n",
    "    missing_keywords = job_keywords.difference(resume_keywords)\n",
    "\n",
    "    # Compute the match percentage\n",
    "    match_percentage = len(matching_keywords) / len(job_keywords) * 100\n",
    "\n",
    "    # Use TF-IDF for cosine similarity comparison\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([resume_text, job_description])\n",
    "    similarity = cosine_similarity(tfidf_matrix)[0, 1] * 100\n",
    "\n",
    "    return {\n",
    "        \"match_percentage\": match_percentage,\n",
    "        \"similarity_score\": similarity,\n",
    "        \"matching_keywords\": matching_keywords,\n",
    "        \"missing_keywords\": missing_keywords\n",
    "    }\n",
    "\n",
    "# Main execution with synthetic data\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Resume and Job Description Evaluator with NLP Enhancements ===\")\n",
    "\n",
    "    # Generate synthetic test data\n",
    "    synthetic_resume = generate_synthetic_resume()\n",
    "    synthetic_job_desc = generate_synthetic_job_description()\n",
    "\n",
    "    print(\"\\nSynthetic Resume:\")\n",
    "    print(synthetic_resume)\n",
    "    print(\"\\nSynthetic Job Description:\")\n",
    "    print(synthetic_job_desc)\n",
    "\n",
    "    # Evaluate the resume\n",
    "    feedback = evaluate_resume(synthetic_resume, synthetic_job_desc)\n",
    "\n",
    "    # Display results\n",
    "    print(\"\\n=== Feedback ===\")\n",
    "    print(f\"Match Percentage: {feedback['match_percentage']:.2f}%\")\n",
    "    print(f\"Cosine Similarity: {feedback['similarity_score']:.2f}\")\n",
    "    print(f\"Matching Keywords: {', '.join(feedback['matching_keywords'])}\")\n",
    "    print(f\"Missing Keywords: {', '.join(feedback['missing_keywords'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e8f7e-c712-44b7-94d8-d5126fdc1bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82488d25-ad49-49da-8b21-492e1954cef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.8.3)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (8.3.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (2.5.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.47.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.26.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.2)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Using cached numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Using cached numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
      "Installing collected packages: numpy, sentence-transformers\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.0.2 sentence-transformers-3.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\~~mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n",
      "pennylane-qiskit 0.39.1 requires sympy<1.13, but you have sympy 1.13.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy sentence-transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88f5b30d-5389-400b-b990-9da09291594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_14260\\4274166632.py:7: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n",
      "Similarity Score: 0.8236\n",
      "\n",
      "Good Match, but some improvements could be made:\n",
      "- Focus on aligning your work experience more closely with the job role requirements.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Disable TensorFlow eager execution compatibility warning\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Disable the symlink warning for Huggingface cache\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "\n",
    "class ResumeJobEvaluator:\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        return text\n",
    "\n",
    "    def get_similarity_score(self, resume, job_description):\n",
    "        resume_clean = self.clean_text(resume)\n",
    "        job_clean = self.clean_text(job_description)\n",
    "\n",
    "        resume_embedding = self.model.encode(resume_clean, convert_to_tensor=True)\n",
    "        job_embedding = self.model.encode(job_clean, convert_to_tensor=True)\n",
    "\n",
    "        similarity = util.cos_sim(resume_embedding, job_embedding).item()\n",
    "        return similarity\n",
    "\n",
    "    def provide_feedback(self, resume, job_description):\n",
    "        similarity_score = self.get_similarity_score(resume, job_description)\n",
    "        print(f\"Similarity Score: {similarity_score:.4f}\")\n",
    "\n",
    "        if similarity_score < 0.7:\n",
    "            print(\"\\nFeedback for Improvement:\")\n",
    "            print(\"- Your experience may not closely match the job description.\")\n",
    "            print(\"- Highlight more relevant skills and experiences.\")\n",
    "        elif similarity_score < 0.85:\n",
    "            print(\"\\nGood Match, but some improvements could be made:\")\n",
    "            print(\"- Focus on aligning your work experience more closely with the job role requirements.\")\n",
    "        else:\n",
    "            print(\"\\nExcellent match! Your resume aligns well with the job description.\")\n",
    "\n",
    "# Define synthetic datasets for testing\n",
    "synthetic_resume = \"\"\"\n",
    "Experienced software engineer with a strong background in machine learning and NLP. \n",
    "Proficient in Python, PyTorch, and TensorFlow. Worked on multiple AI-driven projects.\n",
    "Skills: Python, Machine Learning, NLP, Data Science, TensorFlow, PyTorch\n",
    "\"\"\"\n",
    "\n",
    "synthetic_job_description = \"\"\"\n",
    "Looking for a Machine Learning Engineer with expertise in Natural Language Processing (NLP), Python, \n",
    "TensorFlow, and PyTorch. Must have hands-on experience working with transformer models and AI projects.\n",
    "\"\"\"\n",
    "\n",
    "evaluator = ResumeJobEvaluator()\n",
    "evaluator.provide_feedback(synthetic_resume, synthetic_job_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccbd251e-5e86-4c74-9aa4-39edb8a27d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.8069\n",
      "\n",
      "Good Match, but some improvements could be made:\n",
      "- Focus on aligning your work experience more closely with the job role requirements.\n"
     ]
    }
   ],
   "source": [
    "synthetic_resume = \"\"\"\n",
    "Data Scientist with expertise in machine learning, deep learning, and natural language processing. Proficient in Python, Scikit-learn, Keras, and Pandas. Experience working on large-scale data processing and predictive modeling projects.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "synthetic_job_description = \"\"\"\n",
    "We are seeking a Data Scientist with a strong background in machine learning, NLP, and deep learning. Must be proficient in Python, Scikit-learn, TensorFlow, and data analysis tools. Experience with predictive modeling, large-scale data processing, and cloud deployment.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "evaluator = ResumeJobEvaluator()\n",
    "evaluator.provide_feedback(synthetic_resume, synthetic_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "168e3035-c5ef-469f-b0c9-44545d9aa67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.5333\n",
      "\n",
      "Feedback for Improvement:\n",
      "- Your experience may not closely match the job description.\n",
      "- Highlight more relevant skills and experiences.\n"
     ]
    }
   ],
   "source": [
    "synthetic_resume = \"\"\"\n",
    "Marketing Specialist with experience in content creation, digital marketing, and SEO. Proficient in tools like Google Analytics, Adobe Creative Suite, and social media platforms. Knowledge of basic data analysis but not focused on machine learning or deep learning.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "synthetic_job_description = \"\"\"\n",
    "We are seeking a Data Scientist with a strong background in machine learning, NLP, and deep learning. Must be proficient in Python, Scikit-learn, TensorFlow, and data analysis tools. Experience with predictive modeling, large-scale data processing, and cloud deployment.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "evaluator = ResumeJobEvaluator()\n",
    "evaluator.provide_feedback(synthetic_resume, synthetic_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a955d-4f6c-4ea1-97c3-028a6a80ad01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
